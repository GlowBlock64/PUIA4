{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analýza sentimentu v příspěvcích a komentářích na sociálních sítích\n",
    "Tým: Ondřej Chmelík, Martin Vondráček, mentor Ing. Jan Lehečka, Ph.D.\n",
    "\n",
    "## Abstrakt\n",
    "Cílem tohoto projektu je analyzovat komentáře ze sociálních sítí a klasifikovat jejich rizikovost (jak pravděpodobné je, že daný komentář vyvolá negativní reakce v odpovědích na daný komentář). Pro klasifikaci použijeme moderní transformerové jazykové modely. Výsledné natrénované modely následně otestujeme na příspěvcích na sociálních sítích (Twitter/X, Reddit). Tento proces může dobře posloužit k vyhledání “rizikových faktorů” – může se jednat o konkrétní témata vyvolávající nevhodné a agresivní reakce nebo detekci toxicity ve větších komunitách (například v subredditech na Redditu).\n",
    "\n",
    "Projekt má široké využití v praxi – například při moderování online diskuzí a filtrování nevhodných příspěvků a komentářů, kde může posloužit při předvídání nevhodných odezev a jejich předejití (například předběžné upozornění pro moderátory diskuzí, blokování vláken atp.). Naším cílem je nejen vytvořit přesný klasifikátor, ale také pochopit jeho možnosti a omezení v různých kontextech.\n",
    "\n",
    "## Postup při řešení problematiky\n",
    "Pro zpracování projektu jsme použili následující zdroje:\n",
    "\n",
    "Modely:\n",
    "- BERT Large Uncased\n",
    "\n",
    "Datasety:\n",
    "- Twitter Emotions Classification Dataset\n",
    "- GoEmotions\n",
    "\n",
    "Původně jsme zamýšleli využít dataset GoEmotions ke kompletnímu natrénování finálního modelu, avšak vzhledem k nespolehlivosti labelů v tomto datasetu (až 30% vzorků má chybné labely) jsme byli nuceni změnit strategii a využít komplexnějšího přístupu. Nejprve jsme natrénovali normální klasifikační model na rozpoznávání emocí na Twitter Emotions Classification datasetu a následně tento model využili k přelabelování datasetu GoEmotions, který již obsahuje stromovou strukturu. Na té jsme pak natrénovali finální klasifikační model, který už vyhodnocuje rizikovost samotných komentářů (jak pravděpodobné je, že daný komentář vyvolá negativní reakce).\n",
    "\n",
    "### Trénování základního modelu\n",
    "Program pro trénování základního modelu je uložen v notebooku [base_model.ipynb](base_model.ipynb). Zkoušeli jsme různé parametry pro trénování (změny learning rate, změny batch size, použití pouhé části datasetu) a zároveň i porovnali výsledek trénování pro celý model a pouze pro klasifikační hlavičku. Trénování celého modelu nakonec dosáhlo lepších výsledků na validačním datasetu, tudíž jsme tento model použili při dalším postupu (složka emotion_model_biglr_full).\n",
    "\n",
    "Základní model lze manuálně otestovat v notebooku [base_test_manual.ipynb](base_test_manual.ipynb)\n",
    "\n",
    "### Trénování finálního modelu\n",
    "Základní model jsme následně využili v notebooku [goemotions_relabel.ipynb](goemotions_relabel.ipynb) k přelabelování datasetu GoEmotions pro naše potřeby. V notebooku [parent_model.ipynb](parent_model.ipynb) jsme následně provedli samotné zpracování nově olabelovaného datasetu a natrénování finálního modelu. Stromová struktura v datasetu GoEmotions se ukázala jako nedostatečná a výsledná užitečná část datasetu byla příliš malá pro naše účely (~200 vzorků), tudíž jsme dataset uměle rozšířili.\n",
    "\n",
    "Pro trénování jsme opět vyzkoušeli různé parametry. Původně měl model problém s overfittingem, což jsme vyřešili přidáním weight decay. Natrénovaný model dosáhl na validačním datasetu přesnosti mezi 75-80 % a F1 skóre kolem 0.8, jak lze vidět v přiložené tabulce níže.\n",
    "\n",
    "|Epoch|Training loss|Validation loss|Accuracy|F1|Precision|Recall|\n",
    "|---|---|---|---|---|---|---|\n",
    "|1|0.672|0.648|0.605|0.752|0.602|1.000|\n",
    "|2|0.579|0.573|0.732|0.799|0.724|0.891|\n",
    "|3|0.448|0.530|0.745|0.797|0.761|0.837|\n",
    "|4|0.548|0.514|0.752|0.793|0.789|0.798|\n",
    "|5|0.417|0.509|0.754|0.792|0.802|0.782|\n",
    "|6|0.603|0.507|0.762|0.804|0.795|0.813|\n",
    "|7|0.395|0.508|0.759|0.798|0.800|0.796|\n",
    "|8|0.443|0.507|0.765|0.806|0.796|0.817|\n",
    "|9|0.458|0.508|0.763|0.803|0.796|0.811|\n",
    "|10|0.409|0.508|0.765|0.806|0.797|0.815|\n",
    "\n",
    "## Příklady komentářů\n",
    "\n",
    "### Příklady klasifikace při manuálním testování různých vstupů\n",
    "|\"I love dinner.\"||\n",
    "|---|---|\n",
    "|Třída 0 (Normální komentář)|87.24%|\n",
    "|Třída 1 (Rizikový komentář)|12.76%|\n",
    "\n",
    "<br>\n",
    "\n",
    "|\"You’re lucky it didn’t get disabled after 10 attempts\"||\n",
    "|---|---|\n",
    "|Třída 0 (Normální komentář)|50.12%|\n",
    "|Třída 1 (Rizikový komentář)|49.88%|\n",
    "\n",
    "<br>\n",
    "\n",
    "|\"Leave the house. By staying there you can only make it worse.\"||\n",
    "|---|---|\n",
    "|Třída 0 (Normální komentář)|13.25%|\n",
    "|Třída 1 (Rizikový komentář)|86.75%|\n",
    "\n",
    "<br>\n",
    "\n",
    "|\"Don't stick your nose into politics again\"||\n",
    "|---|---|\n",
    "|Třída 0 (Normální komentář)|11.30%|\n",
    "|Třída 1 (Rizikový komentář)|88.70%|\n",
    "\n",
    "<br>\n",
    "\n",
    "|\"You have already beaten 99 percent of the people, keep going\"||\n",
    "|---|---|\n",
    "|Třída 0 (Normální komentář)|37.76%|\n",
    "|Třída 1 (Rizikový komentář)|62.24%|\n",
    "\n",
    "### Příklady nesprávně klasifikovaných příspěvků z datasetu\n",
    "|\"Married at first sight!\" (label 0)||\n",
    "|---|---|\n",
    "|Třída 0 (Normální komentář)|17.66%|\n",
    "|Třída 1 (Rizikový komentář)|82.34%|\n",
    "\n",
    "<br>\n",
    "\n",
    "|\"Oh easy leader of the free world\" (label 1)||\n",
    "|---|---|\n",
    "|Třída 0 (Normální komentář)|73.33%|\n",
    "|Třída 1 (Rizikový komentář)|26.67%|\n",
    "\n",
    "\n",
    "Níže je k dispozici kód pro načtení finálního modelu a jeho manuální otestování. Pro relativně jasné vstupy vrátil model očekávané a správné výstupy, každopádně kvůli více stupňům trénování v rámci projektu a omezení ze strany dataestů očekáváme vetěí frekvenci chybných výsledků u komplexnějších vstupů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ondra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "model_path = \"./parent_model\"  # or wherever you saved it\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 (Normal comment): 73.33%\n",
      "Class 1 (Controversial comment): 26.67%\n"
     ]
    }
   ],
   "source": [
    "text = input()\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    softmax_outputs = torch.softmax(logits, dim=1)\n",
    "    predicted_class_id = softmax_outputs.argmax().item()\n",
    "\n",
    "    probs = softmax_outputs[0]\n",
    "    percentages = (probs * 100).tolist()\n",
    "\n",
    "    for i, p in enumerate(percentages):\n",
    "        print(f\"Class {i} ({['Normal comment', 'Controversial comment'][i]}): {p:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
